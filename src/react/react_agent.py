# tasksigma/react/react_agent.py

import logging
import requests

class ReActAgent:
    """
    ReActAgent is responsible for integrating reasoning and action-taking capabilities
    in a large language model (LLM) to interact with external environments and solve tasks.
    """

    def __init__(self, config):
        """
        Initializes the ReActAgent with the given configuration.

        Args:
            config (dict): Configuration parameters for the agent, including API keys,
                           model settings, and environment details.
        """
        self.api_key = config.get('api_key')
        self.model = config.get('model', 'gpt-4')
        self.temperature = config.get('temperature', 0.7)
        self.max_tokens = config.get('max_tokens', 1500)
        self.environment = config.get('environment', {})
        self.agent_name = config.get('agent_name', 'ReActAgent')
        logging.info(f"{self.agent_name} initialized with model {self.model}")

    def reason(self, prompt):
        """
        Generates reasoning based on the provided prompt using the LLM.

        Args:
            prompt (str): The input prompt for the reasoning process.

        Returns:
            str: The reasoning trace generated by the LLM.
        """
        logging.info(f"{self.agent_name} generating reasoning for prompt: {prompt}")
        # Simulate an API call to OpenAI's GPT model
        response = self._call_openai_api(prompt)
        reasoning_trace = response.get('choices', [{}])[0].get('text', '').strip()
        logging.info(f"{self.agent_name} generated reasoning: {reasoning_trace}")
        return reasoning_trace

    def act(self, action):
        """
        Performs an action based on the reasoning, such as querying an external environment.

        Args:
            action (str): The action to be performed.

        Returns:
            dict: The result of the action performed.
        """
        logging.info(f"{self.agent_name} performing action: {action}")
        # Example of interacting with an external environment via an API
        if self.environment.get('type') == 'api':
            result = self._interact_with_environment(action)
        else:
            result = {"error": "Unsupported environment type"}
        logging.info(f"{self.agent_name} received result from action: {result}")
        return result

    def _call_openai_api(self, prompt):
        """
        Internal method to simulate a call to the OpenAI API.

        Args:
            prompt (str): The input prompt for the API call.

        Returns:
            dict: The simulated response from the OpenAI API.
        """
        # This is a placeholder for the actual API call to OpenAI's GPT models.
        return {
            "choices": [
                {
                    "text": "This is a simulated response from the model."
                }
            ]
        }

    def _interact_with_environment(self, action):
        """
        Internal method to interact with an external environment using an API.

        Args:
            action (str): The action or query to send to the external environment.

        Returns:
            dict: The response from the environment.
        """
        try:
            endpoint = self.environment.get('endpoint')
            headers = self.environment.get('headers', {})
            payload = {"action": action}
            response = requests.post(endpoint, json=payload, headers=headers)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            logging.error(f"Failed to interact with environment: {e}")
            return {"error": str(e)}

    def run(self, prompt):
        """
        Executes the full reasoning and acting cycle.

        Args:
            prompt (str): The initial prompt to start the reasoning process.

        Returns:
            dict: The final result after reasoning and acting.
        """
        reasoning_trace = self.reason(prompt)
        action_result = self.act(reasoning_trace)
        return {
            "reasoning": reasoning_trace,
            "result": action_result
        }
